#Рейтинг открытых LLM на русском.

gguf|params|VRAM|temp|OK|сл.корот|ошибки|бред|русский,%|ру+след|лог-ok-1|ошибки-1|лог-ok-2|ошибки-2|ok, %|ИТОГ|comment
---|---|---|---|---|---|---|---|---|р---|---|---|---|---|---|---|---
vikhr-7b-instruct_0.4.Q6_K|7|6,3|0.50|22|6|2|0|93%|83%|12|8|0|20|30%|65%|
saiga_llama3_8b.Q5_0|8|6|0.50|12|0|7|1|60%|60%|17|3|13|7|75%|64%|
Starling-LM-7B-beta-Q5_K_M|7|5,7|0.50|8|3|7|1|58%|50%|19|1|17|3|90%|63%|
vikhr-7b-instruct_0.2.Q6_K|7|6,9|0.50|20|9|1|0|97%|82%|8|15|1|20|20%|61%|
Meta-Llama-3-8B-Instruct.Q5_0_broken|8|6|0.50|12|0|4|0|75%|75%|1|19|12|8|33%|60%|BROKEN.gguf + override pre-tokenizer in llama.cpp
Meta-Llama-3-8B-Instruct-Q5_K_S|8|5,8|0.50|13|0|7|1|62%|62%|7|13|13|7|50%|57%|fixed gguf by bartowski
mixtral-8x7b-instruct-v0.1.Q4_K_M|56|26,3|0.50|13|2|9|2|58%|54%|8|12|9|11|43%|50%|
solar-10.7b-instruct-v1.0.Q5_K_S|11|7,9|0.50|8|0|10|2|40%|40%|9|11|19|1|70%|50%|
suzume-llama-3-8B-multilingual-Q8_0|8|7,8|0.50|9|0|10|0|47%|47%|16|4|6|14|55%|49%|
ggml-c4ai-command-r-35b-v01-iq2_xs|35|13|0.50|5||2|3|50%|50%|13|7|3|17|40%|46%|
mistral-7b-instruct-v0.2.Q6_K|7|6,5|0.50|5|0|8|1|36%|36%|0|20|13|7|33%|34%|
Meta-Llama-3-8B.Q5_0|8|6|0.50|||||||||||||base version likes to go into a loop
vikhr-7b-0.1.Q5_K_M|7|5,8|0.50|||||||||||||
vikhr-7b-instruct_0.2.Q5_0|7|5,6|0.50|16|3|0|0|100%|92%|||||||
vikhr-7b-v0.3.Q5_0|7|5,6|0.50|||||||||||||
